{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Huggingface API call for Flan-T5/base google"
      ],
      "metadata": {
        "id": "lZrSumSciQQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "API_HF_Token=userdata.get('HFtoken')"
      ],
      "metadata": {
        "id": "YYlf79xliYtz"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_HF_Token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "t3CSicRMilWN",
        "outputId": "92cadc06-b53c-43cc-d9c7-a7ba23825221"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id=\"google/flan-t5-base\""
      ],
      "metadata": {
        "id": "sFhP0jmsirPP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inferencing\n",
        "\n",
        "To load the model and use to conduct predictions."
      ],
      "metadata": {
        "id": "NQTLaYvWi_vH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_url=\"https://api-inference.huggingface.co/models/\""
      ],
      "metadata": {
        "id": "DTuDPBM2jAHL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_url=\"https://api-inference.huggingface.co/models/google/flan-t5-base\""
      ],
      "metadata": {
        "id": "9ZzmpoVljY-j"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headers = {\"Authorization\": f\"Bearer {API_HF_Token}\"}"
      ],
      "metadata": {
        "id": "IF3eVluAjtI0"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "def query(payload):\n",
        "    response = requests.post(model_url, headers=headers, json=payload)\n",
        "    print(response)\n",
        "    return response.json()\n"
      ],
      "metadata": {
        "id": "HW5haY1xjgrK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_question= {\"inputs\": \"Translate What is your height in german\"}"
      ],
      "metadata": {
        "id": "ByKT4x1nj6Xl"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output=query(data_question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXPB4MaKkIlS",
        "outputId": "bdf1ce36-90bd-4b5a-8a6c-1ace2b27f353"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erfF2yHekWdn",
        "outputId": "c5c66994-3ffb-4b19-a487-3e22e9d747ac"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Was ist Ihr Höhe in Deutschland?'}]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAm0MKQqktb3",
        "outputId": "7fad9f65-a47c-4856-f1da-2fd720fd9374"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'Was ist Ihr Höhe in Deutschland?'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output[0].get(\"generated_text\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03rckFoLk_RI",
        "outputId": "545f51ac-1fdf-4457-a6a4-f634c62aa26a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Was ist Ihr Höhe in Deutschland?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To load the file in GPU"
      ],
      "metadata": {
        "id": "czBxd0odlcVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install accelerate\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\", device_map=\"auto\")\n",
        "\n",
        "input_text = \"translate English to German: What is your height?\"\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(input_ids)\n",
        "print(tokenizer.decode(outputs[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF73NUv5lE7I",
        "outputId": "ffa0d34d-7500-472e-b029-4e8e824fd991"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pad> Was ist Ihr Height?</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(outputs[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEX15fXBlqlX",
        "outputId": "ab774832-8efe-476e-fbde-d0b05239fe81"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pad> Was ist Ihr Height?</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IQr8MV37l9jy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}